{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3be965ad",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e685ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helperfunctions as hf\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sktime.transformations.panel.padder import PaddingTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GroupKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from sktime.classification.compose import ColumnEnsembleClassifier\n",
    "from sktime.utils.mlflow_sktime import save_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62671aeb",
   "metadata": {},
   "source": [
    "To generate pip requirements.txt:\n",
    "\n",
    "`pip list --format=freeze > requirements.txt`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c4ecff5",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "003109db",
   "metadata": {},
   "source": [
    "## Data Cleaning for Training Set\n",
    "### Set up directory\n",
    "```\n",
    "-- Directory Structure --\n",
    "\n",
    "Main Directory\n",
    "| Code - put code files here: 'Submission.ipynb' and 'helperfunctions.py'\n",
    "| dataPackage - the original dataPackage with training set data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521d4b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directories\n",
    "cwd = os.getcwd()\n",
    "main_dir = os.path.split(cwd)[0]\n",
    "data_ils_dir = os.path.join(main_dir, 'dataPackage', 'task-ils')\n",
    "data_rest_dir = os.path.join(main_dir, 'dataPackage', 'task-rest')\n",
    "data_pkg_dir = os.path.join(main_dir, 'dataPackage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "753f0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory if not exist\n",
    "output_dir = os.path.join(main_dir,'Cleaned Data')\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "# rest data cleaning\n",
    "# rest_output_dir = os.path.join(main_dir,'Cleaned Data Rest')\n",
    "# if not os.path.isdir(rest_output_dir):\n",
    "#     os.makedirs(rest_output_dir)\n",
    "ML_final_output_dir = os.path.join(main_dir,'Data Ready for ML_final')\n",
    "if not os.path.isdir(ML_final_output_dir):\n",
    "    os.makedirs(ML_final_output_dir)\n",
    "\n",
    "ML_validation_output_dir = os.path.join(main_dir,'Data Ready for ML_validation')\n",
    "if not os.path.isdir(ML_validation_output_dir):\n",
    "    os.makedirs(ML_validation_output_dir)\n",
    "\n",
    "model_dir = os.path.join(main_dir,'Trained Models')\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa0e54db",
   "metadata": {},
   "source": [
    "### Cleaning for selected sensors\n",
    "`['lslshimmertorsoacc','lslshimmereda','lslshimmeremg','lslshimmerresp','lslrespitrace','lslshimmerecg']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dceca61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 'cap_name_list', 'level_list', 'sensor_freq_list'\n",
    "cap_name_list = []\n",
    "for cp in os.listdir(data_ils_dir):\n",
    "    if 'cp' in cp:\n",
    "        cap_name_list.append(cp[-5:])\n",
    "\n",
    "cap_name_list = pd.DataFrame(data=cap_name_list, columns=['cp_ID'])\n",
    "cap_name_list.to_csv(os.path.join(data_pkg_dir,'cap_name_list.csv'), index=False)\n",
    "\n",
    "level_list = {'level': ['01B','02B','03B','04B']}\n",
    "level_list = pd.DataFrame(level_list)\n",
    "level_list.to_csv(os.path.join(data_pkg_dir,'level_list.csv'), index=False)\n",
    "\n",
    "sensor_cutoff_freq_list = {\n",
    "    'sensor_name': ['lslshimmertorsoacc','lslshimmereda','lslshimmeremg','lslshimmerresp','lslrespitrace','lslshimmerecg'] ,\n",
    "    'freq': [10,30,5,30,30,30]\n",
    "    }\n",
    "sensor_cutoff_freq_list = pd.DataFrame(sensor_cutoff_freq_list)\n",
    "sensor_cutoff_freq_list.to_csv(os.path.join(data_pkg_dir,'selected_sensor_cutoff_freq.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b5edcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_name_list = pd.read_csv(os.path.join(data_pkg_dir,'cap_name_list.csv'))\n",
    "level_list = pd.read_csv(os.path.join(data_pkg_dir,'level_list.csv'))\n",
    "sensor_freq_list = pd.read_csv(os.path.join(data_pkg_dir,'selected_sensor_cutoff_freq.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b902a85b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp009 01B lslshimmereda 1\n",
      "cp009 01B lslshimmerresp 1\n",
      "cp009 01B lslshimmerecg 1\n",
      "cp009 02B lslshimmereda 1\n",
      "cp009 02B lslshimmerresp 1\n",
      "cp009 02B lslshimmerecg 1\n",
      "cp009 03B lslshimmereda 1\n",
      "cp009 03B lslshimmerresp 1\n",
      "cp009 03B lslshimmerecg 1\n",
      "cp009 04B lslshimmereda 1\n",
      "cp009 04B lslshimmerresp 1\n",
      "cp009 04B lslshimmerecg 1\n",
      "cp028 01B lslshimmeremg 3\n"
     ]
    }
   ],
   "source": [
    "# data cleaning for ils data - output as 1 file per csv\n",
    "# failed files are printed as output\n",
    "for cap in cap_name_list['cp_ID']:\n",
    "    for level in level_list['level']:\n",
    "        for sensor in sensor_freq_list['sensor_name']:\n",
    "            try:\n",
    "                data_csv_list = hf.get_dirs_to_csv(data_ils_dir, cap, level, sensor)\n",
    "                run = 0\n",
    "                for csv_dir in data_csv_list:\n",
    "                    run = run + 1\n",
    "                    sr = hf.get_csv_freq(csv_dir)\n",
    "                    cut_off_freq = sensor_freq_list.loc[sensor_freq_list['sensor_name'] == sensor, 'freq'].iloc[0]\n",
    "                    dsr = np.rint(sr/(cut_off_freq*2))\n",
    "                    df = pd.read_csv(csv_dir)\n",
    "                    # remove from df before simulation start and after simulation ends (12 Dec new)\n",
    "                    head, tail = hf.get_head_tail_time_to_remove(csv_dir)\n",
    "                    # remove before start\n",
    "                    if head > 0:\n",
    "                        head_rows = head * sr\n",
    "                        head_rows = int(head_rows) + (head_rows % 1 > 0)\n",
    "                        df = df.drop(df.index[:head_rows])\n",
    "                    #remove after stop\n",
    "                    if tail > 0:\n",
    "                        tail_rows = tail * sr\n",
    "                        tail_rows = int(tail_rows) + (tail_rows % 1 > 0)\n",
    "                        df = df.drop(df.index[-tail_rows:])\n",
    "                    # end of 12 Dec New added code\n",
    "                    df_out = pd.DataFrame()\n",
    "                    cols, times = [], []\n",
    "                    for column in df:\n",
    "                        if column != 'time_dn':\n",
    "                            cols.append(column)\n",
    "                            df1 = df[column]\n",
    "                            X = np.fft.fft(df1,axis=0)\n",
    "                            X_lpf = X\n",
    "                            X_lpf[cut_off_freq*sr:] = 0\n",
    "                            Y_lpf = np.fft.ifft(X_lpf,axis=0)\n",
    "                            Y_lpf = Y_lpf.real\n",
    "                            Y_dsp = Y_lpf[::int(dsr)]\n",
    "                            df_out = pd.concat([df_out, pd.DataFrame(Y_dsp)], axis=1)\n",
    "                            \n",
    "                    df_out.columns = cols\n",
    "                    # add time column\n",
    "                    for i in range(df_out.shape[0]):\n",
    "                        times.append(i*1/(cut_off_freq*2))\n",
    "                    df_out.insert(0, 'Time', times)\n",
    "                    output_csv = os.path.join(output_dir, f\"{sensor}_{level}_{cap}_{run}.csv\")\n",
    "                    df_out.to_csv(output_csv, index=False)\n",
    "            except:\n",
    "                print (cap, level, sensor, run)\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe20b562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp009 000 lslshimmereda 1\n",
      "cp009 000 lslshimmerresp 1\n",
      "cp009 000 lslshimmerecg 1\n",
      "cp028 000 lslshimmeremg 2\n",
      "cp042 000 lslshimmeremg 1\n"
     ]
    }
   ],
   "source": [
    "## DID NOT USE REST DATA ##\n",
    "# data cleaning for rest data - output as 1 file per csv\n",
    "# failed files are printed as output\n",
    "# level = '000'\n",
    "# for cap in cap_name_list['cp_ID']:\n",
    "#         for sensor in sensor_freq_list['sensor_name']:\n",
    "#             try:\n",
    "#                 data_csv_list = hf.get_dirs_to_csv(data_rest_dir, cap, level, sensor)\n",
    "#                 run = 0\n",
    "#                 for csv_dir in data_csv_list:\n",
    "#                     run = run + 1\n",
    "#                     sr = hf.get_csv_freq(csv_dir)\n",
    "#                     cut_off_freq = sensor_freq_list.loc[sensor_freq_list['sensor_name'] == sensor, 'freq'].iloc[0]\n",
    "#                     dsr = np.rint(sr/(cut_off_freq*2))\n",
    "#                     df = pd.read_csv(csv_dir)\n",
    "\n",
    "#                     df_out = pd.DataFrame()\n",
    "#                     cols, times = [], []\n",
    "#                     for column in df:\n",
    "#                         if column != 'time_dn':\n",
    "#                             cols.append(column)\n",
    "#                             df1 = df[column]\n",
    "#                             X = np.fft.fft(df1,axis=0)\n",
    "#                             X_lpf = X\n",
    "#                             X_lpf[cut_off_freq*sr:] = 0\n",
    "#                             Y_lpf = np.fft.ifft(X_lpf,axis=0)\n",
    "#                             Y_lpf = Y_lpf.real\n",
    "#                             Y_dsp = Y_lpf[::int(dsr)]\n",
    "#                             df_out = pd.concat([df_out, pd.DataFrame(Y_dsp)], axis=1)\n",
    "\n",
    "#                             # output_csv = os.path.join(rest_output_dir, f\"{sensor}_{column}_{level}_{cap}_{run}.csv\")\n",
    "#                             # df_out = pd.DataFrame(Y_dsp)\n",
    "#                             # df_out.columns = [column]\n",
    "#                             # df_out.to_csv(output_csv, index=False)\n",
    "                        \n",
    "#                     df_out.columns = cols\n",
    "#                     # add time column\n",
    "#                     for i in range(df_out.shape[0]):\n",
    "#                         times.append(i*1/(cut_off_freq*2))\n",
    "#                     df_out.insert(0, 'Time', times)\n",
    "#                     output_csv = os.path.join(rest_output_dir, f\"{sensor}_{level}_{cap}_{run}.csv\")\n",
    "#                     df_out.to_csv(output_csv, index=False)\n",
    "#             except:\n",
    "#                  print (cap, level, sensor, run)\n",
    "#                  pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdf033d9",
   "metadata": {},
   "source": [
    "### Move HTC Vive Eye Data to clean data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12210459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp003 01B lslhtcviveeye 1\n",
      "cp003 02B lslhtcviveeye 1\n",
      "cp003 03B lslhtcviveeye 1\n",
      "cp003 04B lslhtcviveeye 1\n",
      "cp027 01B lslhtcviveeye 1\n",
      "cp027 03B lslhtcviveeye 1\n"
     ]
    }
   ],
   "source": [
    "# Timestamps are in original matlab format\n",
    "# Test data only\n",
    "# Failed files are printed as output\n",
    "\n",
    "sensor = 'lslhtcviveeye'\n",
    "\n",
    "for cap in cap_name_list['cp_ID']:\n",
    "    for level in level_list['level']:\n",
    "        try:\n",
    "            data_csv_list = hf.get_dirs_to_csv(data_ils_dir, cap, level, sensor)\n",
    "            run = 0\n",
    "            for csv_dir in data_csv_list:\n",
    "                run = run + 1\n",
    "                sr = hf.get_csv_freq(csv_dir)\n",
    "                df = pd.read_csv(csv_dir)\n",
    "                # remove from df before simulation start and after simulation ends (12 Dec new)\n",
    "                head, tail = hf.get_head_tail_time_to_remove(csv_dir)\n",
    "                # remove before start\n",
    "                if head > 0:\n",
    "                    head_rows = head * sr\n",
    "                    head_rows = int(head_rows) + (head_rows % 1 > 0)\n",
    "                    df = df.drop(df.index[:head_rows])\n",
    "                # remove after stop\n",
    "                if tail > 0:\n",
    "                    tail_rows = tail * sr\n",
    "                    tail_rows = int(tail_rows) + (tail_rows % 1 > 0)\n",
    "                    df = df.drop(df.index[-tail_rows:])\n",
    "                output_csv = os.path.join(output_dir, f\"{sensor}_{level}_{cap}_{run}.csv\")\n",
    "                df.to_csv(output_csv, index=False)\n",
    "        except:\n",
    "            print (cap, level, sensor, run)\n",
    "            pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10428368",
   "metadata": {},
   "source": [
    "## Generate 5 folds for train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "190258ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 31, 32]\n",
      "[5, 10, 15, 20, 25, 30, 33]\n",
      "33\n",
      "\n",
      "[1, 2, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33]\n",
      "[6, 11, 16, 17, 21, 26, 31]\n",
      "33\n",
      "\n",
      "[3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 33]\n",
      "[1, 2, 7, 12, 22, 27, 32]\n",
      "33\n",
      "\n",
      "[1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33]\n",
      "[3, 8, 13, 18, 23, 28]\n",
      "33\n",
      "\n",
      "[1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33]\n",
      "[4, 9, 14, 19, 24, 29]\n",
      "33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subjects2 = [i for i in range(1,34)]\n",
    "\n",
    "# Split\n",
    "train, test = [], []\n",
    "\n",
    "grpkfold = GroupKFold(n_splits=5)\n",
    "for train_i, test_i in grpkfold.split(X=subjects2, groups=subjects2):\n",
    "    train.append(train_i)\n",
    "    test.append(test_i)\n",
    "\n",
    "train_splits, test_splits = {}, {}\n",
    "\n",
    "for i, fold in enumerate(train):\n",
    "    train_splits[i] = []\n",
    "    for j in fold:\n",
    "        train_splits[i].append(subjects2[j])\n",
    "\n",
    "for i, fold in enumerate(test):\n",
    "    test_splits[i] = []\n",
    "    for j in fold:\n",
    "        test_splits[i].append(subjects2[j])\n",
    "\n",
    "# Check splits\n",
    "for i in range(5):\n",
    "    print(train_splits[i])\n",
    "    print(test_splits[i])\n",
    "    print(len(train_splits[i]) + len(test_splits[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fee528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'C:\\Users\\shiuh\\Documents\\Pilot Performance Data Science Comp\\Cleaned Data'\n",
    "target_dir = r'C:\\Users\\shiuh\\Documents\\Pilot Performance Data Science Comp\\Data Ready for ML_folds'\n",
    "\n",
    "# Get list of subjects\n",
    "data_files = hf.get_all_data_csv_filenames(data_dir)\n",
    "split_files = [i.split('_') for i in data_files]\n",
    "subjects = [i[2] for i in split_files]\n",
    "subjects = list(set(subjects))\n",
    "subjects.sort()\n",
    "\n",
    "# Split\n",
    "train, test = [], []\n",
    "\n",
    "grpkfold = GroupKFold(n_splits=5)\n",
    "for train_i, test_i in grpkfold.split(X=subjects, groups=subjects):\n",
    "    train.append(train_i)\n",
    "    test.append(test_i)\n",
    "\n",
    "train_splits, test_splits = {}, {}\n",
    "\n",
    "for i, fold in enumerate(train):\n",
    "    train_splits[i] = []\n",
    "    for j in fold:\n",
    "        train_splits[i].append(subjects[j])\n",
    "\n",
    "for i, fold in enumerate(test):\n",
    "    test_splits[i] = []\n",
    "    for j in fold:\n",
    "        test_splits[i].append(subjects[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a677a3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cp003', 'cp005', 'cp006', 'cp008', 'cp009', 'cp012', 'cp013', 'cp014', 'cp015', 'cp017', 'cp018', 'cp019', 'cp020', 'cp022', 'cp023', 'cp024', 'cp025', 'cp026', 'cp027', 'cp029', 'cp030', 'cp031', 'cp032', 'cp035', 'cp036', 'cp037', 'cp038', 'cp042']\n",
      "\n",
      "['cp004', 'cp011', 'cp016', 'cp028', 'cp033', 'cp039', 'cp043']\n",
      "35\n",
      "\n",
      "['cp003', 'cp004', 'cp005', 'cp006', 'cp008', 'cp011', 'cp012', 'cp014', 'cp016', 'cp017', 'cp018', 'cp019', 'cp022', 'cp023', 'cp024', 'cp025', 'cp026', 'cp028', 'cp029', 'cp030', 'cp032', 'cp033', 'cp035', 'cp036', 'cp037', 'cp039', 'cp042', 'cp043']\n",
      "\n",
      "['cp009', 'cp013', 'cp015', 'cp020', 'cp027', 'cp031', 'cp038']\n",
      "35\n",
      "\n",
      "['cp003', 'cp004', 'cp005', 'cp006', 'cp009', 'cp011', 'cp012', 'cp013', 'cp015', 'cp016', 'cp017', 'cp018', 'cp020', 'cp022', 'cp025', 'cp027', 'cp028', 'cp029', 'cp030', 'cp031', 'cp032', 'cp033', 'cp035', 'cp036', 'cp038', 'cp039', 'cp042', 'cp043']\n",
      "\n",
      "['cp008', 'cp014', 'cp019', 'cp023', 'cp024', 'cp026', 'cp037']\n",
      "35\n",
      "\n",
      "['cp003', 'cp004', 'cp005', 'cp008', 'cp009', 'cp011', 'cp013', 'cp014', 'cp015', 'cp016', 'cp017', 'cp019', 'cp020', 'cp022', 'cp023', 'cp024', 'cp026', 'cp027', 'cp028', 'cp029', 'cp031', 'cp032', 'cp033', 'cp035', 'cp037', 'cp038', 'cp039', 'cp043']\n",
      "\n",
      "['cp006', 'cp012', 'cp018', 'cp025', 'cp030', 'cp036', 'cp042']\n",
      "35\n",
      "\n",
      "['cp004', 'cp006', 'cp008', 'cp009', 'cp011', 'cp012', 'cp013', 'cp014', 'cp015', 'cp016', 'cp018', 'cp019', 'cp020', 'cp023', 'cp024', 'cp025', 'cp026', 'cp027', 'cp028', 'cp030', 'cp031', 'cp033', 'cp036', 'cp037', 'cp038', 'cp039', 'cp042', 'cp043']\n",
      "\n",
      "['cp003', 'cp005', 'cp017', 'cp022', 'cp029', 'cp032', 'cp035']\n",
      "35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check splits\n",
    "for i in range(5):\n",
    "    print(train_splits[i])\n",
    "    print()\n",
    "    print(test_splits[i])\n",
    "    print(len(train_splits[i]) + len(test_splits[i]))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e624e843",
   "metadata": {},
   "source": [
    "# Individual data types"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5df19056",
   "metadata": {},
   "source": [
    "## EMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b529a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did not use"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5df19056",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did not use"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5df19056",
   "metadata": {},
   "source": [
    "## ECG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128afd4a",
   "metadata": {},
   "source": [
    "### Validate model on training data folds\n",
    "#### Generate folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8db67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of runs detected: 323\n",
      "X shape: (323, 3, 48024)\n",
      "y shape: (323,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmerecg_standard_padtransform0.npy\n",
      "\ty_train_lslshimmerecg_standard_padtransform0.npy\n",
      "\n",
      "Number of runs detected: 335\n",
      "X shape: (335, 3, 48024)\n",
      "y shape: (335,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmerecg_standard_padtransform1.npy\n",
      "\ty_train_lslshimmerecg_standard_padtransform1.npy\n",
      "\n",
      "Number of runs detected: 323\n",
      "X shape: (323, 3, 48024)\n",
      "y shape: (323,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmerecg_standard_padtransform2.npy\n",
      "\ty_train_lslshimmerecg_standard_padtransform2.npy\n",
      "\n",
      "Number of runs detected: 324\n",
      "X shape: (324, 3, 48024)\n",
      "y shape: (324,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmerecg_standard_padtransform3.npy\n",
      "\ty_train_lslshimmerecg_standard_padtransform3.npy\n",
      "\n",
      "Number of runs detected: 323\n",
      "X shape: (323, 3, 48024)\n",
      "y shape: (323,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmerecg_standard_padtransform4.npy\n",
      "\ty_train_lslshimmerecg_standard_padtransform4.npy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate folds of training data\n",
    "\n",
    "data_dir = os.path.join(main_dir,'Cleaned Data')\n",
    "target_dir = os.path.join(main_dir,'Data Ready for ML_validation')\n",
    "hz = 60\n",
    "sensor = 'lslshimmerecg'\n",
    "level = ''\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for i in train_splits:\n",
    "    file_suffix = f'train_lslshimmerecg_standard_padtransform{i}'\n",
    "    subject = train_splits[i]\n",
    "    hf.generate_ml_data(data_dir, target_dir, file_suffix, scaler, hz, sensor, subject, level)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da43daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of runs detected: 84\n",
      "X shape: (84, 3, 48024)\n",
      "y shape: (84,)\n",
      "Saved files:\n",
      "\tX_test_lslshimmerecg_standard_padtransform0.npy\n",
      "\ty_test_lslshimmerecg_standard_padtransform0.npy\n",
      "\n",
      "Number of runs detected: 72\n",
      "X shape: (72, 3, 48024)\n",
      "y shape: (72,)\n",
      "Saved files:\n",
      "\tX_test_lslshimmerecg_standard_padtransform1.npy\n",
      "\ty_test_lslshimmerecg_standard_padtransform1.npy\n",
      "\n",
      "Number of runs detected: 84\n",
      "X shape: (84, 3, 48024)\n",
      "y shape: (84,)\n",
      "Saved files:\n",
      "\tX_test_lslshimmerecg_standard_padtransform2.npy\n",
      "\ty_test_lslshimmerecg_standard_padtransform2.npy\n",
      "\n",
      "Number of runs detected: 83\n",
      "X shape: (83, 3, 48024)\n",
      "y shape: (83,)\n",
      "Saved files:\n",
      "\tX_test_lslshimmerecg_standard_padtransform3.npy\n",
      "\ty_test_lslshimmerecg_standard_padtransform3.npy\n",
      "\n",
      "Number of runs detected: 84\n",
      "X shape: (84, 3, 48024)\n",
      "y shape: (84,)\n",
      "Saved files:\n",
      "\tX_test_lslshimmerecg_standard_padtransform4.npy\n",
      "\ty_test_lslshimmerecg_standard_padtransform4.npy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate folds of test data\n",
    "\n",
    "for i in test_splits:\n",
    "    file_suffix = f'test_lslshimmerecg_standard_padtransform{i}'\n",
    "    subject = test_splits[i]\n",
    "    hf.generate_ml_data(data_dir, target_dir, file_suffix, scaler, hz, sensor, subject, level)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0477e",
   "metadata": {},
   "source": [
    "#### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf017501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.interval_based import SupervisedTimeSeriesForest\n",
    "\n",
    "def ecg_folds(n_estimators=250, n_jobs=-1, random_state=42, result_CV = None):\n",
    "    data_dir = os.path.join(main_dir,'Data Ready for ML_validation')\n",
    "    probabilities = {}\n",
    "\n",
    "    for i in range(5):\n",
    "        X_train = np.load(data_dir + '\\\\' + f'X_train_lslshimmerecg_standard_padtransform{i}.npy')\n",
    "        y_train = np.load(data_dir + '\\\\' + f'y_train_lslshimmerecg_standard_padtransform{i}.npy')\n",
    "        X_test = np.load(data_dir + '\\\\' + f'X_test_lslshimmerecg_standard_padtransform{i}.npy')\n",
    "        y_test = np.load(data_dir + '\\\\' + f'y_test_lslshimmerecg_standard_padtransform{i}.npy')\n",
    "\n",
    "        # only use first 2 columns of data on la_ra and ll_ra.\n",
    "        clf = ColumnEnsembleClassifier(\n",
    "            estimators=[\n",
    "                (\"est1\", SupervisedTimeSeriesForest(n_estimators, n_jobs, random_state), [0]),\n",
    "                (\"est2\", SupervisedTimeSeriesForest(n_estimators, n_jobs, random_state), [1])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred_proba_SupervisedTimeSeriesForest = clf.predict_proba(X_test)\n",
    "        probabilities[i] = y_pred_proba_SupervisedTimeSeriesForest\n",
    "        # Log results\n",
    "        class_list = [0,1,2,3]\n",
    "        result_CV = hf.log_result(f'Set {i}', class_list, y_test, y_pred_proba_SupervisedTimeSeriesForest, result_CV)\n",
    "        \n",
    "        print(f'\\rFold {i} complete', end='')\n",
    "    print()\n",
    "    return result_CV, probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb733c79",
   "metadata": {},
   "source": [
    "#### Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f8007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 45min 32s\n",
      "Wall time: 1h 17min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.361264\n",
       "AUC_score         0.648099\n",
       "F1_score          0.321160\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, _ = ecg_folds(100, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58271b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 47min 27s\n",
      "Wall time: 1h 33min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.362880\n",
       "AUC_score         0.653857\n",
       "F1_score          0.321408\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, _ = ecg_folds(150, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd4ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 48min 37s\n",
      "Wall time: 1h 50min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.372375\n",
       "AUC_score         0.653808\n",
       "F1_score          0.333089\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, _ = ecg_folds(200, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e00580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 49min 27s\n",
      "Wall time: 2h 4min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.383090\n",
       "AUC_score         0.656757\n",
       "F1_score          0.342569\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, _ = ecg_folds(240, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0dff8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 49min 17s\n",
      "Wall time: 2h 12min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.390261\n",
       "AUC_score         0.655580\n",
       "F1_score          0.351113\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, _ = ecg_folds(250, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d11b054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 50min 4s\n",
      "Wall time: 2h 11min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.375182\n",
       "AUC_score         0.655679\n",
       "F1_score          0.334513\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, _ = ecg_folds(260, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfdbf18",
   "metadata": {},
   "source": [
    "### Generate probabilities for ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57df76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result, probabilities = ecg_folds(250, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652fbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(probabilities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14c0ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of runs detected: 84\n",
      "Number of runs detected: 72\n",
      "Number of runs detected: 84\n",
      "Number of runs detected: 83\n",
      "Number of runs detected: 84\n"
     ]
    }
   ],
   "source": [
    "# Get run info\n",
    "\n",
    "data_dir = os.path.join(main_dir,'Cleaned Data')\n",
    "hz = 60\n",
    "sensor = 'lslshimmerecg'\n",
    "level = ''\n",
    "\n",
    "df_combined = pd.DataFrame()\n",
    "split_df_list = []\n",
    "for i in range(5):\n",
    "    subject = test_splits[i]\n",
    "    df_runs = hf.get_df_runs(data_dir, sensor, subject, level, True)\n",
    "    df_runs = df_runs.drop('time', axis=1)\n",
    "    df_proba = pd.DataFrame(probabilities[i])\n",
    "    df_proba.columns = ['lslshimmerecg_01B', 'lslshimmerecg_02B', 'lslshimmerecg_03B', 'lslshimmerecg_04B']\n",
    "    df_cur = pd.concat([df_runs, df_proba], axis=1)\n",
    "    split_df_list.append(df_cur)\n",
    "    df_combined = pd.concat([df_combined, df_cur], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e6ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>run</th>\n",
       "      <th>lslshimmerresp_01B</th>\n",
       "      <th>lslshimmerresp_02B</th>\n",
       "      <th>lslshimmerresp_03B</th>\n",
       "      <th>lslshimmerresp_04B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cp003</td>\n",
       "      <td>01B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cp003</td>\n",
       "      <td>01B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cp003</td>\n",
       "      <td>01B</td>\n",
       "      <td>3</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cp003</td>\n",
       "      <td>02B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cp003</td>\n",
       "      <td>02B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>cp043</td>\n",
       "      <td>03B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>cp043</td>\n",
       "      <td>03B</td>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>cp043</td>\n",
       "      <td>04B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>cp043</td>\n",
       "      <td>04B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>cp043</td>\n",
       "      <td>04B</td>\n",
       "      <td>3</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject difficulty run  lslshimmerresp_01B  lslshimmerresp_02B  \\\n",
       "0     cp003        01B   1                0.44                0.22   \n",
       "1     cp003        01B   2                0.24                0.22   \n",
       "2     cp003        01B   3                0.46                0.24   \n",
       "3     cp003        02B   1                0.20                0.28   \n",
       "4     cp003        02B   2                0.12                0.22   \n",
       "..      ...        ...  ..                 ...                 ...   \n",
       "402   cp043        03B   2                0.04                0.28   \n",
       "403   cp043        03B   3                0.26                0.30   \n",
       "404   cp043        04B   1                0.08                0.28   \n",
       "405   cp043        04B   2                0.04                0.22   \n",
       "406   cp043        04B   3                0.16                0.20   \n",
       "\n",
       "     lslshimmerresp_03B  lslshimmerresp_04B  \n",
       "0                  0.14                0.20  \n",
       "1                  0.22                0.32  \n",
       "2                  0.18                0.12  \n",
       "3                  0.28                0.24  \n",
       "4                  0.42                0.24  \n",
       "..                  ...                 ...  \n",
       "402                0.44                0.24  \n",
       "403                0.20                0.24  \n",
       "404                0.36                0.28  \n",
       "405                0.46                0.28  \n",
       "406                0.34                0.30  \n",
       "\n",
       "[407 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine probabilities with run info and save it\n",
    "\n",
    "target_dir = os.path.join(main_dir,'Data Ensembled')\n",
    "\n",
    "df_combined_lslshimmerecg = df_combined.copy()\n",
    "df_combined_lslshimmerecg = df_combined_lslshimmerecg.sort_values(['subject','difficulty','run'], axis = 0)\n",
    "df_combined_lslshimmerecg = df_combined_lslshimmerecg.reset_index(drop = True)\n",
    "df_combined_lslshimmerecg.to_csv(target_dir+r'\\lslshimmerecg_ensembled_training.csv', index=False)\n",
    "df_combined_lslshimmerecg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f77bf6d8",
   "metadata": {},
   "source": [
    "### Generate combined numpy data file for ML model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "364e5d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of runs detected: 407\n",
      "X shape: (407, 3, 48024)\n",
      "y shape: (407,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmerecg_standard_padtransform.npy\n",
      "\ty_train_lslshimmerecg_standard_padtransform.npy\n"
     ]
    }
   ],
   "source": [
    "# Generate full training data for respiration from Shimmer\n",
    "\n",
    "data_dir = os.path.join(main_dir,'Cleaned Data')\n",
    "target_dir = os.path.join(main_dir,'Data Ready for ML_final')\n",
    "hz = 60\n",
    "sensor = 'lslshimmerecg'\n",
    "subject = ''\n",
    "level = ''\n",
    "\n",
    "# StandardScaler\n",
    "file_suffix = 'train_lslshimmerecg_standard_padtransform'\n",
    "scaler = StandardScaler()\n",
    "hf.generate_ml_data(data_dir, target_dir, file_suffix, scaler, hz, sensor, subject, level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bc9399f",
   "metadata": {},
   "source": [
    "### Train model on full set of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d68b0a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.interval_based import SupervisedTimeSeriesForest\n",
    "\n",
    "data_dir = os.path.join(main_dir,'Data Ready for ML_final')\n",
    "model_dir = os.path.join(main_dir,'Trained Models')\n",
    "\n",
    "X_train = np.load(data_dir + '\\\\' + 'X_train_lslshimmerecg_standard_padtransform.npy')\n",
    "y_train = np.load(data_dir + '\\\\' + 'y_train_lslshimmerecg_standard_padtransform.npy')\n",
    "\n",
    "# only use first 2 columns of data on la_ra and ll_ra.\n",
    "clf = ColumnEnsembleClassifier(\n",
    "    estimators=[\n",
    "        (\"est1\", SupervisedTimeSeriesForest(n_estimators=250, n_jobs=-1, random_state=42), [0]),\n",
    "        (\"est2\", SupervisedTimeSeriesForest(n_estimators=250, n_jobs=-1, random_state=42), [1])\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "with open(model_dir + r'\\shimmerECG.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8087a443",
   "metadata": {},
   "source": [
    "### Load model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d8bd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "# with open(model_dir + r'\\shimmerECG.pkl', 'rb') as f:\n",
    "#     clf = pickle.load(f)\n",
    "\n",
    "# y_pred_proba = clf.predict_proba(X_train)\n",
    "# y_pred = clf.predict(X_train)\n",
    "\n",
    "# acc = accuracy_score(y_train, y_pred)\n",
    "# auc = roc_auc_score(y_train, y_pred_proba, multi_class='ovr', average = 'macro')\n",
    "# f1 = f1_score(y_train, y_pred, average='macro')\n",
    "\n",
    "# print(acc)\n",
    "# print(auc)\n",
    "# print(f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5df19056",
   "metadata": {},
   "source": [
    "## Respiration (from Shimmer Device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a870de0",
   "metadata": {},
   "source": [
    "### Validate model on training data folds\n",
    "#### Generate folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6a7018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of runs detected: 323\n",
      "X shape: (323, 1, 48024)\n",
      "y shape: (323,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmerresp_standard_padtransform0.npy\n",
      "\ty_train_lslshimmerresp_standard_padtransform0.npy\n",
      "\n",
      "Number of runs detected: 335\n",
      "X shape: (335, 1, 48024)\n",
      "y shape: (335,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmerresp_standard_padtransform1.npy\n",
      "\ty_train_lslshimmerresp_standard_padtransform1.npy\n",
      "\n",
      "Number of runs detected: 323\n",
      "X shape: (323, 1, 48024)\n",
      "y shape: (323,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmerresp_standard_padtransform2.npy\n",
      "\ty_train_lslshimmerresp_standard_padtransform2.npy\n",
      "\n",
      "Number of runs detected: 324\n",
      "X shape: (324, 1, 48024)\n",
      "y shape: (324,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmerresp_standard_padtransform3.npy\n",
      "\ty_train_lslshimmerresp_standard_padtransform3.npy\n",
      "\n",
      "Number of runs detected: 323\n",
      "X shape: (323, 1, 48024)\n",
      "y shape: (323,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmerresp_standard_padtransform4.npy\n",
      "\ty_train_lslshimmerresp_standard_padtransform4.npy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate folds of training data\n",
    "\n",
    "data_dir = os.path.join(main_dir,'Cleaned Data')\n",
    "target_dir = os.path.join(main_dir,'Data Ready for ML_validation')\n",
    "hz = 60\n",
    "sensor = 'lslshimmerresp'\n",
    "level = ''\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for i in train_splits:\n",
    "    file_suffix = f'train_lslshimmerresp_standard_padtransform{i}'\n",
    "    subject = train_splits[i]\n",
    "    hf.generate_ml_data(data_dir, target_dir, file_suffix, scaler, hz, sensor, subject, level)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac2acff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of runs detected: 84\n",
      "X shape: (84, 1, 48024)\n",
      "y shape: (84,)\n",
      "Saved files:\n",
      "\tX_test_lslshimmerresp_standard_padtransform0.npy\n",
      "\ty_test_lslshimmerresp_standard_padtransform0.npy\n",
      "\n",
      "Number of runs detected: 72\n",
      "X shape: (72, 1, 48024)\n",
      "y shape: (72,)\n",
      "Saved files:\n",
      "\tX_test_lslshimmerresp_standard_padtransform1.npy\n",
      "\ty_test_lslshimmerresp_standard_padtransform1.npy\n",
      "\n",
      "Number of runs detected: 84\n",
      "X shape: (84, 1, 48024)\n",
      "y shape: (84,)\n",
      "Saved files:\n",
      "\tX_test_lslshimmerresp_standard_padtransform2.npy\n",
      "\ty_test_lslshimmerresp_standard_padtransform2.npy\n",
      "\n",
      "Number of runs detected: 83\n",
      "X shape: (83, 1, 48024)\n",
      "y shape: (83,)\n",
      "Saved files:\n",
      "\tX_test_lslshimmerresp_standard_padtransform3.npy\n",
      "\ty_test_lslshimmerresp_standard_padtransform3.npy\n",
      "\n",
      "Number of runs detected: 84\n",
      "X shape: (84, 1, 48024)\n",
      "y shape: (84,)\n",
      "Saved files:\n",
      "\tX_test_lslshimmerresp_standard_padtransform4.npy\n",
      "\ty_test_lslshimmerresp_standard_padtransform4.npy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate folds of test data\n",
    "\n",
    "for i in test_splits:\n",
    "    file_suffix = f'test_lslshimmerresp_standard_padtransform{i}'\n",
    "    subject = test_splits[i]\n",
    "    hf.generate_ml_data(data_dir, target_dir, file_suffix, scaler, hz, sensor, subject, level)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d511e2",
   "metadata": {},
   "source": [
    "#### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af15c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.interval_based import SupervisedTimeSeriesForest\n",
    "\n",
    "def respshimmer_folds(n_estimators=40, n_jobs=-1, random_state=42, result_CV = None):\n",
    "    data_dir = os.path.join(main_dir,'Data Ready for ML_validation')\n",
    "    probabilities = {}\n",
    "\n",
    "    for i in range(5):\n",
    "        X_train = np.load(data_dir + '\\\\' + f'X_train_lslshimmerresp_standard_padtransform{i}.npy')\n",
    "        y_train = np.load(data_dir + '\\\\' + f'y_train_lslshimmerresp_standard_padtransform{i}.npy')\n",
    "        X_test = np.load(data_dir + '\\\\' + f'X_test_lslshimmerresp_standard_padtransform{i}.npy')\n",
    "        y_test = np.load(data_dir + '\\\\' + f'y_test_lslshimmerresp_standard_padtransform{i}.npy')\n",
    "\n",
    "        clf = SupervisedTimeSeriesForest(n_estimators, n_jobs, random_state)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred_proba_SupervisedTimeSeriesForest = clf.predict_proba(X_test)\n",
    "        probabilities[i] = y_pred_proba_SupervisedTimeSeriesForest\n",
    "        # Log results\n",
    "        class_list = [0,1,2,3]\n",
    "        result_CV = hf.log_result(f'Set {i}', class_list, y_test, y_pred_proba_SupervisedTimeSeriesForest, result_CV)\n",
    "        \n",
    "        print(f'\\rFold {i} complete', end='')\n",
    "    print()\n",
    "    return result_CV, probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e07705",
   "metadata": {},
   "source": [
    "#### Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a1279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 12.4 s\n",
      "Wall time: 8min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.373111\n",
       "AUC_score         0.630991\n",
       "F1_score          0.354807\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, _ = respshimmer_folds(40, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef6c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 17.2 s\n",
      "Wall time: 9min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.402931\n",
       "AUC_score         0.647100\n",
       "F1_score          0.378989\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, _ = respshimmer_folds(50, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd8f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 24.2 s\n",
      "Wall time: 11min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.373848\n",
       "AUC_score         0.644333\n",
       "F1_score          0.347194\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, _ = respshimmer_folds(60, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e4d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 29.3 s\n",
      "Wall time: 12min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.370731\n",
       "AUC_score         0.644125\n",
       "F1_score          0.342514\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, _ = respshimmer_folds(70, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43819995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 38.3 s\n",
      "Wall time: 15min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.375464\n",
       "AUC_score         0.651196\n",
       "F1_score          0.347768\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, _ = respshimmer_folds(80, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e4ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 44.7 s\n",
      "Wall time: 18min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.378356\n",
       "AUC_score         0.648205\n",
       "F1_score          0.348122\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, _ = respshimmer_folds(90, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ed069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 55.3 s\n",
      "Wall time: 19min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.384648\n",
       "AUC_score         0.645720\n",
       "F1_score          0.354331\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, _ = respshimmer_folds(100, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd64ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 1min 6s\n",
      "Wall time: 19min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.379518\n",
       "AUC_score         0.645322\n",
       "F1_score          0.349614\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, _ = respshimmer_folds(110, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f7550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 2min 49s\n",
      "Wall time: 35min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.371806\n",
       "AUC_score         0.646544\n",
       "F1_score          0.344480\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, _ = respshimmer_folds(200, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40d01dff",
   "metadata": {},
   "source": [
    "### Generate probabilities for ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd85e2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 16.8 s\n",
      "Wall time: 8min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.402931\n",
       "AUC_score         0.647100\n",
       "F1_score          0.378989\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result, probabilities = respshimmer_folds(50, -1, 42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe82ec80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3\n",
       "0   0.58  0.10  0.14  0.18\n",
       "1   0.54  0.10  0.12  0.24\n",
       "2   0.42  0.14  0.18  0.26\n",
       "3   0.36  0.22  0.28  0.14\n",
       "4   0.24  0.18  0.22  0.36\n",
       "..   ...   ...   ...   ...\n",
       "79  0.04  0.28  0.44  0.24\n",
       "80  0.26  0.30  0.20  0.24\n",
       "81  0.08  0.28  0.36  0.28\n",
       "82  0.04  0.22  0.46  0.28\n",
       "83  0.16  0.20  0.34  0.30\n",
       "\n",
       "[84 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(probabilities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d021acd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of runs detected: 84\n",
      "Number of runs detected: 72\n",
      "Number of runs detected: 84\n",
      "Number of runs detected: 83\n",
      "Number of runs detected: 84\n"
     ]
    }
   ],
   "source": [
    "# Get run info\n",
    "\n",
    "data_dir = os.path.join(main_dir,'Cleaned Data')\n",
    "hz = 60\n",
    "sensor = 'lslshimmerresp'\n",
    "level = ''\n",
    "\n",
    "df_combined = pd.DataFrame()\n",
    "split_df_list = []\n",
    "for i in range(5):\n",
    "    subject = test_splits[i]\n",
    "    df_runs = hf.get_df_runs(data_dir, sensor, subject, level, True)\n",
    "    df_runs = df_runs.drop('time', axis=1)\n",
    "    df_proba = pd.DataFrame(probabilities[i])\n",
    "    df_proba.columns = ['lslshimmerresp_01B', 'lslshimmerresp_02B', 'lslshimmerresp_03B', 'lslshimmerresp_04B']\n",
    "    df_cur = pd.concat([df_runs, df_proba], axis=1)\n",
    "    split_df_list.append(df_cur)\n",
    "    df_combined = pd.concat([df_combined, df_cur], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbaea25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>run</th>\n",
       "      <th>lslshimmerresp_01B</th>\n",
       "      <th>lslshimmerresp_02B</th>\n",
       "      <th>lslshimmerresp_03B</th>\n",
       "      <th>lslshimmerresp_04B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cp003</td>\n",
       "      <td>01B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cp003</td>\n",
       "      <td>01B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cp003</td>\n",
       "      <td>01B</td>\n",
       "      <td>3</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cp003</td>\n",
       "      <td>02B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cp003</td>\n",
       "      <td>02B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>cp043</td>\n",
       "      <td>03B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>cp043</td>\n",
       "      <td>03B</td>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>cp043</td>\n",
       "      <td>04B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>cp043</td>\n",
       "      <td>04B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>cp043</td>\n",
       "      <td>04B</td>\n",
       "      <td>3</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject difficulty run  lslshimmerresp_01B  lslshimmerresp_02B  \\\n",
       "0     cp003        01B   1                0.44                0.22   \n",
       "1     cp003        01B   2                0.24                0.22   \n",
       "2     cp003        01B   3                0.46                0.24   \n",
       "3     cp003        02B   1                0.20                0.28   \n",
       "4     cp003        02B   2                0.12                0.22   \n",
       "..      ...        ...  ..                 ...                 ...   \n",
       "402   cp043        03B   2                0.04                0.28   \n",
       "403   cp043        03B   3                0.26                0.30   \n",
       "404   cp043        04B   1                0.08                0.28   \n",
       "405   cp043        04B   2                0.04                0.22   \n",
       "406   cp043        04B   3                0.16                0.20   \n",
       "\n",
       "     lslshimmerresp_03B  lslshimmerresp_04B  \n",
       "0                  0.14                0.20  \n",
       "1                  0.22                0.32  \n",
       "2                  0.18                0.12  \n",
       "3                  0.28                0.24  \n",
       "4                  0.42                0.24  \n",
       "..                  ...                 ...  \n",
       "402                0.44                0.24  \n",
       "403                0.20                0.24  \n",
       "404                0.36                0.28  \n",
       "405                0.46                0.28  \n",
       "406                0.34                0.30  \n",
       "\n",
       "[407 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine probabilities with run info and save it\n",
    "\n",
    "target_dir = os.path.join(main_dir,'Data Ensembled')\n",
    "\n",
    "df_combined_lslshimmerresp = df_combined.copy()\n",
    "df_combined_lslshimmerresp = df_combined_lslshimmerresp.sort_values(['subject','difficulty','run'], axis = 0)\n",
    "df_combined_lslshimmerresp = df_combined_lslshimmerresp.reset_index(drop = True)\n",
    "df_combined_lslshimmerresp.to_csv(target_dir+r'\\lslshimmerresp_ensembled_training.csv', index=False)\n",
    "df_combined_lslshimmerresp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf3abd87",
   "metadata": {},
   "source": [
    "### Generate combined numpy data file for ML model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f8e9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(407, 4)\n",
      "407\n",
      "X shape: (407, 1, 48024)\n",
      "y shape: (407,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmerresp_standard_padtransform.npy\n",
      "\ty_train_lslshimmerresp_standard_padtransform.npy\n"
     ]
    }
   ],
   "source": [
    "# Generate full training data for respiration from Shimmer\n",
    "\n",
    "data_dir = os.path.join(main_dir,'Cleaned Data')\n",
    "target_dir = os.path.join(main_dir,'Data Ready for ML_final')\n",
    "hz = 60\n",
    "sensor = 'lslshimmerresp'\n",
    "subject = ''\n",
    "level = ''\n",
    "\n",
    "# StandardScaler\n",
    "file_suffix = 'train_lslshimmerresp_standard_padtransform'\n",
    "scaler = StandardScaler()\n",
    "hf.generate_ml_data(data_dir, target_dir, file_suffix, scaler, hz, sensor, subject, level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0cb00d9",
   "metadata": {},
   "source": [
    "### Train model on full set of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78ece49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.interval_based import SupervisedTimeSeriesForest\n",
    "\n",
    "data_dir = os.path.join(main_dir,'Data Ready for ML_final')\n",
    "model_dir = os.path.join(main_dir,'Trained Models')\n",
    "\n",
    "X_train = np.load(data_dir + '\\\\' + 'X_train_lslshimmerresp_standard_padtransform.npy')\n",
    "y_train = np.load(data_dir + '\\\\' + 'y_train_lslshimmerresp_standard_padtransform.npy')\n",
    "\n",
    "clf = SupervisedTimeSeriesForest(n_estimators=40, n_jobs=-1, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "with open(model_dir + r'\\shimmerResp.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21ae1dd1",
   "metadata": {},
   "source": [
    "### Load model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99805b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "# with open(model_dir + r'\\shimmerResp.pkl', 'rb') as f:\n",
    "#     clf = pickle.load(f)\n",
    "\n",
    "# y_pred_proba = clf.predict_proba(X_train)\n",
    "# y_pred = clf.predict(X_train)\n",
    "\n",
    "# acc = accuracy_score(y_train, y_pred)\n",
    "# auc = roc_auc_score(y_train, y_pred_proba, multi_class='ovr', average = 'macro')\n",
    "# f1 = f1_score(y_train, y_pred, average='macro')\n",
    "\n",
    "# print(acc)\n",
    "# print(auc)\n",
    "# print(f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5df19056",
   "metadata": {},
   "source": [
    "## Respiration (from Respitrace Device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did not use"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5df19056",
   "metadata": {},
   "source": [
    "## TorsoACC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "559277fe",
   "metadata": {},
   "source": [
    "### Generate combined numpy data file for ML model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa6a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390, 4)\n",
      "390\n",
      "X shape: (390, 3, 15969)\n",
      "y shape: (390,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmertorsoacc_minmax_padtransform.npy\n",
      "\ty_train_lslshimmertorsoacc_minmax_padtransform.npy\n",
      "(390, 4)\n",
      "390\n",
      "X shape: (390, 3, 15969)\n",
      "y shape: (390,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmertorsoacc_standard_padtransform.npy\n",
      "\ty_train_lslshimmertorsoacc_standard_padtransform.npy\n"
     ]
    }
   ],
   "source": [
    "# Generate full training data for TorsoACC\n",
    "\n",
    "data_dir = r'C:\\Users\\shiuh\\Documents\\Pilot Performance Data Science Comp\\Cleaned Data'\n",
    "target_dir = r'C:\\Users\\shiuh\\Documents\\Pilot Performance Data Science Comp\\Data Ready for ML_final'\n",
    "hz = 20\n",
    "sensor = 'lslshimmertorsoacc'\n",
    "subject = ''\n",
    "level = ''\n",
    "\n",
    "# MinMaxScaler\n",
    "file_suffix = 'train_lslshimmertorsoacc_minmax_padtransform'\n",
    "scaler = MinMaxScaler()\n",
    "hf.generate_ml_data(data_dir, target_dir, file_suffix, scaler, hz, sensor, subject, level)\n",
    "\n",
    "# StandardScaler\n",
    "file_suffix = 'train_lslshimmertorsoacc_standard_padtransform'\n",
    "scaler = StandardScaler()\n",
    "hf.generate_ml_data(data_dir, target_dir, file_suffix, scaler, hz, sensor, subject, level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02769e1c",
   "metadata": {},
   "source": [
    "### Train model on full set of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27988a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 22min 16s\n",
      "Wall time: 22min 53s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnEnsembleClassifier(estimators=[(&#x27;est1&#x27;,\n",
       "                                      SignatureClassifier(random_state=42,\n",
       "                                                          window_length=15,\n",
       "                                                          window_name=&#x27;sliding&#x27;,\n",
       "                                                          window_step=15),\n",
       "                                      [0]),\n",
       "                                     (&#x27;est2&#x27;,\n",
       "                                      SignatureClassifier(random_state=42,\n",
       "                                                          window_length=15,\n",
       "                                                          window_name=&#x27;sliding&#x27;,\n",
       "                                                          window_step=15),\n",
       "                                      [1]),\n",
       "                                     (&#x27;est3&#x27;,\n",
       "                                      SignatureClassifier(random_state=42,\n",
       "                                                          window_length=15,\n",
       "                                                          window_name=&#x27;sliding&#x27;,\n",
       "                                                          window_step=15),\n",
       "                                      [2])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnEnsembleClassifier</label><div class=\"sk-toggleable__content\"><pre>ColumnEnsembleClassifier(estimators=[(&#x27;est1&#x27;,\n",
       "                                      SignatureClassifier(random_state=42,\n",
       "                                                          window_length=15,\n",
       "                                                          window_name=&#x27;sliding&#x27;,\n",
       "                                                          window_step=15),\n",
       "                                      [0]),\n",
       "                                     (&#x27;est2&#x27;,\n",
       "                                      SignatureClassifier(random_state=42,\n",
       "                                                          window_length=15,\n",
       "                                                          window_name=&#x27;sliding&#x27;,\n",
       "                                                          window_step=15),\n",
       "                                      [1]),\n",
       "                                     (&#x27;est3&#x27;,\n",
       "                                      SignatureClassifier(random_state=42,\n",
       "                                                          window_length=15,\n",
       "                                                          window_name=&#x27;sliding&#x27;,\n",
       "                                                          window_step=15),\n",
       "                                      [2])])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnEnsembleClassifier(estimators=[('est1',\n",
       "                                      SignatureClassifier(random_state=42,\n",
       "                                                          window_length=15,\n",
       "                                                          window_name='sliding',\n",
       "                                                          window_step=15),\n",
       "                                      [0]),\n",
       "                                     ('est2',\n",
       "                                      SignatureClassifier(random_state=42,\n",
       "                                                          window_length=15,\n",
       "                                                          window_name='sliding',\n",
       "                                                          window_step=15),\n",
       "                                      [1]),\n",
       "                                     ('est3',\n",
       "                                      SignatureClassifier(random_state=42,\n",
       "                                                          window_length=15,\n",
       "                                                          window_name='sliding',\n",
       "                                                          window_step=15),\n",
       "                                      [2])])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sktime.classification.feature_based import SignatureClassifier\n",
    "\n",
    "data_dir = r'C:\\Users\\shiuh\\Documents\\Pilot Performance Data Science Comp\\Data Ready for ML_final'\n",
    "model_dir = r'C:\\Users\\shiuh\\Documents\\Pilot Performance Data Science Comp\\Trained Models'\n",
    "\n",
    "X_train = np.load(data_dir + '\\\\' + 'X_train_lslshimmertorsoacc_standard_padtransform.npy')\n",
    "y_train = np.load(data_dir + '\\\\' + 'y_train_lslshimmertorsoacc_standard_padtransform.npy')\n",
    "\n",
    "clf = ColumnEnsembleClassifier(\n",
    "    estimators=[\n",
    "        (\"est1\", SignatureClassifier(estimator=None, augmentation_list=('basepoint', 'addtime'), window_name=\"sliding\", window_length=15, window_step=15, rescaling=None, sig_tfm='signature', depth=4, random_state=42), [0]),\n",
    "        (\"est2\", SignatureClassifier(estimator=None, augmentation_list=('basepoint', 'addtime'), window_name=\"sliding\", window_length=15, window_step=15, rescaling=None, sig_tfm='signature', depth=4, random_state=42), [1]),\n",
    "        (\"est3\", SignatureClassifier(estimator=None, augmentation_list=('basepoint', 'addtime'), window_name=\"sliding\", window_length=15, window_step=15, rescaling=None, sig_tfm='signature', depth=4, random_state=42), [2]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "with open(model_dir + r'\\torsoACC.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d7138ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# with open(model_dir + r'\\torsoACC2.pkl', 'rb') as f:\n",
    "#     clf = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adb3fb4f",
   "metadata": {},
   "source": [
    "### Validate model on training data folds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4b38a06",
   "metadata": {},
   "source": [
    "#### Generate folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25e16b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of runs detected: 306\n",
      "X shape: (306, 3, 15969)\n",
      "y shape: (306,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmertorsoacc_standard_padtransform0.npy\n",
      "\ty_train_lslshimmertorsoacc_standard_padtransform0.npy\n",
      "\n",
      "Number of runs detected: 318\n",
      "X shape: (318, 3, 15969)\n",
      "y shape: (318,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmertorsoacc_standard_padtransform1.npy\n",
      "\ty_train_lslshimmertorsoacc_standard_padtransform1.npy\n",
      "\n",
      "Number of runs detected: 311\n",
      "X shape: (311, 3, 15969)\n",
      "y shape: (311,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmertorsoacc_standard_padtransform2.npy\n",
      "\ty_train_lslshimmertorsoacc_standard_padtransform2.npy\n",
      "\n",
      "Number of runs detected: 307\n",
      "X shape: (307, 3, 15969)\n",
      "y shape: (307,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmertorsoacc_standard_padtransform3.npy\n",
      "\ty_train_lslshimmertorsoacc_standard_padtransform3.npy\n",
      "\n",
      "Number of runs detected: 318\n",
      "X shape: (318, 3, 15969)\n",
      "y shape: (318,)\n",
      "Saved files:\n",
      "\tX_train_lslshimmertorsoacc_standard_padtransform4.npy\n",
      "\ty_train_lslshimmertorsoacc_standard_padtransform4.npy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate folds of training data\n",
    "\n",
    "data_dir = r'C:\\Users\\shiuh\\Documents\\Pilot Performance Data Science Comp\\Cleaned Data'\n",
    "target_dir = r'C:\\Users\\shiuh\\Documents\\Pilot Performance Data Science Comp\\Data Ready for ML_validation'\n",
    "hz = 20\n",
    "sensor = 'lslshimmertorsoacc'\n",
    "level = ''\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for i in train_splits:\n",
    "    file_suffix = f'train_lslshimmertorsoacc_standard_padtransform{i}'\n",
    "    subject = train_splits[i]\n",
    "    hf.generate_ml_data(data_dir, target_dir, file_suffix, scaler, hz, sensor, subject, level)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2534b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of runs detected: 84\n",
      "X shape: (84, 3, 15969)\n",
      "y shape: (84,)\n",
      "Saved files:\n",
      "\tX_test_lslshimmertorsoacc_standard_padtransform0.npy\n",
      "\ty_test_lslshimmertorsoacc_standard_padtransform0.npy\n",
      "\n",
      "Number of runs detected: 72\n",
      "X shape: (72, 3, 15969)\n",
      "y shape: (72,)\n",
      "Saved files:\n",
      "\tX_test_lslshimmertorsoacc_standard_padtransform1.npy\n",
      "\ty_test_lslshimmertorsoacc_standard_padtransform1.npy\n",
      "\n",
      "Number of runs detected: 79\n",
      "X shape: (79, 3, 15969)\n",
      "y shape: (79,)\n",
      "Saved files:\n",
      "\tX_test_lslshimmertorsoacc_standard_padtransform2.npy\n",
      "\ty_test_lslshimmertorsoacc_standard_padtransform2.npy\n",
      "\n",
      "Number of runs detected: 83\n",
      "X shape: (83, 3, 15969)\n",
      "y shape: (83,)\n",
      "Saved files:\n",
      "\tX_test_lslshimmertorsoacc_standard_padtransform3.npy\n",
      "\ty_test_lslshimmertorsoacc_standard_padtransform3.npy\n",
      "\n",
      "Number of runs detected: 72\n",
      "X shape: (72, 3, 15969)\n",
      "y shape: (72,)\n",
      "Saved files:\n",
      "\tX_test_lslshimmertorsoacc_standard_padtransform4.npy\n",
      "\ty_test_lslshimmertorsoacc_standard_padtransform4.npy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate folds of test data\n",
    "\n",
    "for i in test_splits:\n",
    "    file_suffix = f'test_lslshimmertorsoacc_standard_padtransform{i}'\n",
    "    subject = test_splits[i]\n",
    "    hf.generate_ml_data(data_dir, target_dir, file_suffix, scaler, hz, sensor, subject, level)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f3fa1cc",
   "metadata": {},
   "source": [
    "#### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307da535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.feature_based import SignatureClassifier\n",
    "\n",
    "def torsoracc_folds(window_name, window_length, window_step, depth, random_state=None, result_CV=None):\n",
    "    path = r'C:\\Users\\shiuh\\Documents\\Pilot Performance Data Science Comp\\Data Ready for ML_validation'\n",
    "    probabilities = {}\n",
    "\n",
    "    for i in range(5):\n",
    "        X_train = np.load(path + '\\\\' + f'X_train_lslshimmertorsoacc_standard_padtransform{i}.npy')\n",
    "        y_train = np.load(path + '\\\\' + f'y_train_lslshimmertorsoacc_standard_padtransform{i}.npy')\n",
    "        X_test = np.load(path + '\\\\' + f'X_test_lslshimmertorsoacc_standard_padtransform{i}.npy')\n",
    "        y_test = np.load(path + '\\\\' + f'y_test_lslshimmertorsoacc_standard_padtransform{i}.npy')\n",
    "\n",
    "        clf = ColumnEnsembleClassifier(\n",
    "            estimators=[\n",
    "                (\"est1\", SignatureClassifier(window_name = window_name, window_length = window_length, window_step = window_step, depth = depth, random_state = random_state), [0]),\n",
    "                (\"est2\", SignatureClassifier(window_name = window_name, window_length = window_length, window_step = window_step, depth = depth, random_state = random_state), [1]),\n",
    "                (\"est3\", SignatureClassifier(window_name = window_name, window_length = window_length, window_step = window_step, depth = depth, random_state = random_state), [2]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred_proba_SignatureClassifier = clf.predict_proba(X_test)\n",
    "        probabilities[i] = y_pred_proba_SignatureClassifier\n",
    "        # Log results\n",
    "        class_list = [0,1,2,3]\n",
    "        result_CV = hf.log_result(f'Set {i}', class_list, y_test, y_pred_proba_SignatureClassifier, result_CV)\n",
    "        \n",
    "        print(f'\\rFold {i} complete', end='')\n",
    "    print()\n",
    "    return result_CV, probabilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "563497f9",
   "metadata": {},
   "source": [
    "#### Generate probabilities for ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "094f1168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 complete\n",
      "CPU times: total: 1h 48min 2s\n",
      "Wall time: 1h 49min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_score    0.400967\n",
       "AUC_score         0.645512\n",
       "F1_score          0.363241\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# result, probabilities = torsoracc_folds(estimator=None, augmentation_list=('basepoint', 'addtime'), window_name=\"sliding\", window_length=15, window_step=15, rescaling=None, sig_tfm='signature', depth=4, random_state=42)\n",
    "result, probabilities = torsoracc_folds(window_name=\"sliding\", window_length=15, window_step=15, depth=4, random_state=42)\n",
    "tmp = pd.DataFrame(result)\n",
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7d2b916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.486667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.193333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.196667</td>\n",
       "      <td>0.256667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.323333</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.196667</td>\n",
       "      <td>0.196667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.103333</td>\n",
       "      <td>0.286667</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.303333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.396667</td>\n",
       "      <td>0.223333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.343333</td>\n",
       "      <td>0.296667</td>\n",
       "      <td>0.260000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3\n",
       "0   0.486667  0.200000  0.120000  0.193333\n",
       "1   0.510000  0.150000  0.120000  0.220000\n",
       "2   0.406667  0.140000  0.196667  0.256667\n",
       "3   0.323333  0.283333  0.196667  0.196667\n",
       "4   0.300000  0.306667  0.183333  0.210000\n",
       "..       ...       ...       ...       ...\n",
       "79  0.103333  0.286667  0.306667  0.303333\n",
       "80  0.246667  0.366667  0.170000  0.216667\n",
       "81  0.076667  0.306667  0.300000  0.316667\n",
       "82  0.100000  0.280000  0.396667  0.223333\n",
       "83  0.100000  0.343333  0.296667  0.260000\n",
       "\n",
       "[84 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(probabilities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34027950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of runs detected: 84\n",
      "Number of runs detected: 72\n",
      "Number of runs detected: 79\n",
      "Number of runs detected: 83\n",
      "Number of runs detected: 72\n"
     ]
    }
   ],
   "source": [
    "data_dir = r'C:\\Users\\shiuh\\Documents\\Pilot Performance Data Science Comp\\Cleaned Data'\n",
    "hz = 20\n",
    "sensor = 'lslshimmertorsoacc'\n",
    "level = ''\n",
    "# subject = test_splits[0]\n",
    "# df_runs = hf.get_df_runs(data_dir, sensor, subject, level, True)\n",
    "\n",
    "df_combined = pd.DataFrame()\n",
    "split_df_list = []\n",
    "for i in range(5):\n",
    "    subject = test_splits[i]\n",
    "    df_runs = hf.get_df_runs(data_dir, sensor, subject, level, True)\n",
    "    df_runs = df_runs.drop('time', axis=1)\n",
    "    df_proba = pd.DataFrame(probabilities[i])\n",
    "    df_proba.columns = ['lslshimmertorsoacc_01B', 'lslshimmertorsoacc_02B', 'lslshimmertorsoacc_03B', 'lslshimmertorsoacc_04B']\n",
    "    df_cur = pd.concat([df_runs, df_proba], axis=1)\n",
    "    split_df_list.append(df_cur)\n",
    "    df_combined = pd.concat([df_combined, df_cur], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e350d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>run</th>\n",
       "      <th>lslshimmertorsoacc_01B</th>\n",
       "      <th>lslshimmertorsoacc_02B</th>\n",
       "      <th>lslshimmertorsoacc_03B</th>\n",
       "      <th>lslshimmertorsoacc_04B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cp004</td>\n",
       "      <td>01B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.193333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cp004</td>\n",
       "      <td>01B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cp004</td>\n",
       "      <td>01B</td>\n",
       "      <td>3</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.196667</td>\n",
       "      <td>0.256667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cp004</td>\n",
       "      <td>02B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.323333</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.196667</td>\n",
       "      <td>0.196667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cp004</td>\n",
       "      <td>02B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>cp043</td>\n",
       "      <td>03B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>0.286667</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.303333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>cp043</td>\n",
       "      <td>03B</td>\n",
       "      <td>3</td>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>cp043</td>\n",
       "      <td>04B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>cp043</td>\n",
       "      <td>04B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.396667</td>\n",
       "      <td>0.223333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>cp043</td>\n",
       "      <td>04B</td>\n",
       "      <td>3</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.343333</td>\n",
       "      <td>0.296667</td>\n",
       "      <td>0.260000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject difficulty run  lslshimmertorsoacc_01B  lslshimmertorsoacc_02B  \\\n",
       "0     cp004        01B   1                0.486667                0.200000   \n",
       "1     cp004        01B   2                0.510000                0.150000   \n",
       "2     cp004        01B   3                0.406667                0.140000   \n",
       "3     cp004        02B   1                0.323333                0.283333   \n",
       "4     cp004        02B   2                0.300000                0.306667   \n",
       "..      ...        ...  ..                     ...                     ...   \n",
       "385   cp043        03B   2                0.103333                0.286667   \n",
       "386   cp043        03B   3                0.246667                0.366667   \n",
       "387   cp043        04B   1                0.076667                0.306667   \n",
       "388   cp043        04B   2                0.100000                0.280000   \n",
       "389   cp043        04B   3                0.100000                0.343333   \n",
       "\n",
       "     lslshimmertorsoacc_03B  lslshimmertorsoacc_04B  \n",
       "0                  0.120000                0.193333  \n",
       "1                  0.120000                0.220000  \n",
       "2                  0.196667                0.256667  \n",
       "3                  0.196667                0.196667  \n",
       "4                  0.183333                0.210000  \n",
       "..                      ...                     ...  \n",
       "385                0.306667                0.303333  \n",
       "386                0.170000                0.216667  \n",
       "387                0.300000                0.316667  \n",
       "388                0.396667                0.223333  \n",
       "389                0.296667                0.260000  \n",
       "\n",
       "[390 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the probabilities\n",
    "\n",
    "target_dir = r'C:\\Users\\shiuh\\Documents\\Pilot Performance Data Science Comp\\Data Ensembled'\n",
    "\n",
    "df_combined_lslshimmertorsoacc = df_combined.copy()\n",
    "df_combined_lslshimmertorsoacc = df_combined_lslshimmertorsoacc.sort_values(['subject','difficulty','run'], axis = 0)\n",
    "df_combined_lslshimmertorsoacc = df_combined_lslshimmertorsoacc.reset_index(drop = True)\n",
    "df_combined_lslshimmertorsoacc.to_csv(target_dir+r'\\lslshimmertorsoacc_ensembled_training.csv', index=False)\n",
    "df_combined_lslshimmertorsoacc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cde5006c",
   "metadata": {},
   "source": [
    "# Ensemble Model\n",
    "## Combine probability tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4634748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "types = defaultdict(lambda: 'float')\n",
    "types['subject'] = 'str'\n",
    "types['difficulty'] = 'str'\n",
    "types['run'] = 'int'\n",
    "\n",
    "path = r'C:\\Users\\shiuh\\Documents\\Pilot Performance Data Science Comp\\Data Ensembled'\n",
    "\n",
    "df_combined_lslshimmerresp = pd.read_csv(path + r'\\lslshimmerresp_ensembled_training.csv', dtype=types)\n",
    "df_combined_lslshimmertorsoacc = pd.read_csv(path + r'\\lslshimmertorsoacc_ensembled_training.csv', dtype=types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5da21823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_combined_lslshimmerresp.merge(df_combined_lslshimmertorsoacc, on=['subject','difficulty','run'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "645edce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>run</th>\n",
       "      <th>lslshimmerresp_01B</th>\n",
       "      <th>lslshimmerresp_02B</th>\n",
       "      <th>lslshimmerresp_03B</th>\n",
       "      <th>lslshimmerresp_04B</th>\n",
       "      <th>lslshimmertorsoacc_01B</th>\n",
       "      <th>lslshimmertorsoacc_02B</th>\n",
       "      <th>lslshimmertorsoacc_03B</th>\n",
       "      <th>lslshimmertorsoacc_04B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cp003</td>\n",
       "      <td>01B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cp003</td>\n",
       "      <td>01B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cp003</td>\n",
       "      <td>01B</td>\n",
       "      <td>3</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cp003</td>\n",
       "      <td>02B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cp003</td>\n",
       "      <td>02B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>cp043</td>\n",
       "      <td>03B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>0.286667</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.303333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>cp043</td>\n",
       "      <td>03B</td>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>cp043</td>\n",
       "      <td>04B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>cp043</td>\n",
       "      <td>04B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.396667</td>\n",
       "      <td>0.223333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>cp043</td>\n",
       "      <td>04B</td>\n",
       "      <td>3</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.343333</td>\n",
       "      <td>0.296667</td>\n",
       "      <td>0.260000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject difficulty  run  lslshimmerresp_01B  lslshimmerresp_02B  \\\n",
       "0     cp003        01B    1                0.44                0.22   \n",
       "1     cp003        01B    2                0.24                0.22   \n",
       "2     cp003        01B    3                0.46                0.24   \n",
       "3     cp003        02B    1                0.20                0.28   \n",
       "4     cp003        02B    2                0.12                0.22   \n",
       "..      ...        ...  ...                 ...                 ...   \n",
       "402   cp043        03B    2                0.04                0.28   \n",
       "403   cp043        03B    3                0.26                0.30   \n",
       "404   cp043        04B    1                0.08                0.28   \n",
       "405   cp043        04B    2                0.04                0.22   \n",
       "406   cp043        04B    3                0.16                0.20   \n",
       "\n",
       "     lslshimmerresp_03B  lslshimmerresp_04B  lslshimmertorsoacc_01B  \\\n",
       "0                  0.14                0.20                     NaN   \n",
       "1                  0.22                0.32                     NaN   \n",
       "2                  0.18                0.12                     NaN   \n",
       "3                  0.28                0.24                     NaN   \n",
       "4                  0.42                0.24                     NaN   \n",
       "..                  ...                 ...                     ...   \n",
       "402                0.44                0.24                0.103333   \n",
       "403                0.20                0.24                0.246667   \n",
       "404                0.36                0.28                0.076667   \n",
       "405                0.46                0.28                0.100000   \n",
       "406                0.34                0.30                0.100000   \n",
       "\n",
       "     lslshimmertorsoacc_02B  lslshimmertorsoacc_03B  lslshimmertorsoacc_04B  \n",
       "0                       NaN                     NaN                     NaN  \n",
       "1                       NaN                     NaN                     NaN  \n",
       "2                       NaN                     NaN                     NaN  \n",
       "3                       NaN                     NaN                     NaN  \n",
       "4                       NaN                     NaN                     NaN  \n",
       "..                      ...                     ...                     ...  \n",
       "402                0.286667                0.306667                0.303333  \n",
       "403                0.366667                0.170000                0.216667  \n",
       "404                0.306667                0.300000                0.316667  \n",
       "405                0.280000                0.396667                0.223333  \n",
       "406                0.343333                0.296667                0.260000  \n",
       "\n",
       "[407 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52b9425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pilotperf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4f164f1c11caade80b54a75f10c7f96a76e64bda5fa916c8ad582db484ad090"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
